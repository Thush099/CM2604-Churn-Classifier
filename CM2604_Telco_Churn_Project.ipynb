{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "a9epx9BtRRAe",
        "GtTD3w77RPLj",
        "ZIHlXS2FTLwr",
        "l-W6s4_6LIJL",
        "JFcMTXtxax0V",
        "0R2xsTHfzNsN",
        "ayyq1MbR0VJn",
        "-Achk6uOT3XZ",
        "yPamV8kKUMbW",
        "hp3gwCqSapDf",
        "SPS77Ntcax40",
        "R92MYaWcbiWO"
      ],
      "mount_file_id": "1AmsA3aq-bgbQV6PWwPxIlDTgXLq-oeb6",
      "authorship_tag": "ABX9TyMH2kLtWvBev86Shqe8ka6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thush099/CM2604-Churn-Classifier/blob/main/CM2604_Telco_Churn_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Telco Customer Churn — Notebook\n",
        "Author: Thushanth Mahendran\n",
        "Course: CM2604 Machine Learning\n"
      ],
      "metadata": {
        "id": "FzEK7Hg6RbTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load libraries and set plotting style."
      ],
      "metadata": {
        "id": "ByLyVToFRpfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZBo7KlC8g0j"
      },
      "outputs": [],
      "source": [
        "# 1. IMPORTS & SETTINGS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import io, os\n",
        "from google.colab import files\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, roc_curve, auc\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set(rc={\"figure.figsize\": (8,5)})\n",
        "\n",
        "print(\"Libraries loaded. TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Upload Data set"
      ],
      "metadata": {
        "id": "fkucipjaQGlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. LOAD CSV FROM COLAB FILE DIRECTORY\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Dataset loaded from:\", csv_path)\n",
        "print(\"Shape (rows, columns):\", df.shape)\n",
        "\n",
        "print(\"\\nFirst three rows:\")\n",
        "display(df.head(3))\n",
        "\n",
        "print(\"\\nColumn dtypes summary:\")\n",
        "print(df.dtypes.value_counts())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FLqYjLEZKQrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect dataset structure\n",
        "Check columns, datatypes and missing values so we know what cleaning is needed."
      ],
      "metadata": {
        "id": "a9epx9BtRRAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 - inspect columns/dtypes/missing\n",
        "print(\"Shape (rows, cols):\", df.shape)\n",
        "print(\"\\nColumns list:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "print(\"\\nDtypes summary:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nMissing values (sorted):\")\n",
        "print(df.isna().sum().sort_values(ascending=False).head(20))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A5z8keYSRI4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quick sanity checks\n",
        "Look for duplicates and unusual values in ID or TotalCharges."
      ],
      "metadata": {
        "id": "GtTD3w77RPLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 - sanity checks\n",
        "# If customerID exists, check duplicates\n",
        "if 'customerID' in df.columns:\n",
        "    print(\"customerID duplicates:\", df['customerID'].duplicated().sum())\n",
        "\n",
        "# Check a few samples from TotalCharges to see formatting\n",
        "if 'TotalCharges' in df.columns:\n",
        "    print(\"\\nTotalCharges sample values:\")\n",
        "    print(df['TotalCharges'].sample(8).values)"
      ],
      "metadata": {
        "id": "I6sDO1NeSuAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning: convert TotalCharges to numeric and remove identifier\n",
        "Convert TotalCharges to numeric (coerce invalid → NaN) and drop very few NaN rows.\n",
        "Also drop customerID (identifier)."
      ],
      "metadata": {
        "id": "ZIHlXS2FTLwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 - clean TotalCharges and drop ID\n",
        "if 'TotalCharges' in df.columns and df['TotalCharges'].dtype == 'object':\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "    print(\"TotalCharges NaNs after coercion:\", df['TotalCharges'].isna().sum())\n",
        "\n",
        "# If only a tiny fraction missing, drop them and report\n",
        "if 'TotalCharges' in df.columns:\n",
        "    n_missing = df['TotalCharges'].isna().sum()\n",
        "    if n_missing > 0 and n_missing / len(df) < 0.01:\n",
        "        df = df.dropna(subset=['TotalCharges']).reset_index(drop=True)\n",
        "        print(\"Dropped rows with missing TotalCharges. New shape:\", df.shape)\n",
        "    elif n_missing > 0:\n",
        "        print(\"Warning: several TotalCharges missing; consider imputation instead of dropping.\")\n",
        "\n",
        "# Drop ID column if present\n",
        "if 'customerID' in df.columns:\n",
        "    df = df.drop(columns=['customerID'])\n",
        "    print(\"Dropped customerID column. Shape now:\", df.shape)\n"
      ],
      "metadata": {
        "id": "PFIafuw5TOx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode target and identify feature types\n",
        "Encode Churn to 0/1 and show which columns are numeric and which are categorical."
      ],
      "metadata": {
        "id": "l-W6s4_6LIJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 - target encoding and feature lists\n",
        "if 'Churn' not in df.columns:\n",
        "    raise ValueError(\"No 'Churn' column found — check dataset.\")\n",
        "df['Churn'] = df['Churn'].map({'No':0, 'Yes':1})\n",
        "\n",
        "# Detect numeric and categorical\n",
        "numeric_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "if 'Churn' in numeric_cols:\n",
        "    numeric_cols.remove('Churn')\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Numeric columns (count):\", len(numeric_cols))\n",
        "print(numeric_cols)\n",
        "print(\"\\nCategorical columns (count):\", len(categorical_cols))\n",
        "print(categorical_cols)\n",
        "print(\"\\nChurn distribution (proportion):\")\n",
        "print(df['Churn'].value_counts(normalize=True).round(3))"
      ],
      "metadata": {
        "id": "3TUi__a8LHJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA: class balance and some feature relationships\n",
        "Plot churn counts and a couple of numeric feature comparisons."
      ],
      "metadata": {
        "id": "JFcMTXtxax0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 - EDA plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Churn counts\n",
        "plt.figure()\n",
        "sns.countplot(data=df, x='Churn')\n",
        "plt.title('Churn counts (0=No, 1=Yes)')\n",
        "plt.show()\n",
        "\n",
        "# Tenure, MonthlyCharges, TotalCharges if present\n",
        "for col in ['tenure','MonthlyCharges','TotalCharges']:\n",
        "    if col in df.columns:\n",
        "        plt.figure()\n",
        "        sns.boxplot(data=df, x='Churn', y=col)\n",
        "        plt.title(f'{col} by Churn')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "rkDuXJ7xa3hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA: churn distribution and numeric feature comparisons (boxplots)"
      ],
      "metadata": {
        "id": "ruMvo2WBbhAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 - categorical vs churn\n",
        "plot_cols = ['Contract','InternetService','PaymentMethod','PaperlessBilling']\n",
        "for c in plot_cols:\n",
        "    if c in df.columns:\n",
        "        plt.figure(figsize=(8,4))\n",
        "        sns.countplot(data=df, x=c, hue='Churn')\n",
        "        plt.title(f'{c} vs Churn')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "8ZFkmIyVbvUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train/test split\n",
        "Create stratified train/test split (80/20) so class proportions are preserved in both sets."
      ],
      "metadata": {
        "id": "0R2xsTHfzNsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9 - train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(columns=['Churn'])\n",
        "y = df['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n",
        "print(\"Train churn rate:\", y_train.mean(), \"Test churn rate:\", y_test.mean())"
      ],
      "metadata": {
        "id": "egGPP-cKzW4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing pipeline\n",
        "Build ColumnTransformer: median imputation + scaling for numeric, most_frequent + one-hot for categorical."
      ],
      "metadata": {
        "id": "ayyq1MbR0VJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 - preprocessing pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# if SeniorCitizen shows up as object, convert it\n",
        "if 'SeniorCitizen' in X_train.columns and X_train['SeniorCitizen'].dtype == 'object':\n",
        "    X_train['SeniorCitizen'] = X_train['SeniorCitizen'].astype(int)\n",
        "    X_test['SeniorCitizen'] = X_test['SeniorCitizen'].astype(int)\n",
        "    if 'SeniorCitizen' in categorical_cols:\n",
        "        categorical_cols.remove('SeniorCitizen')\n",
        "        numeric_cols.append('SeniorCitizen')\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, [c for c in numeric_cols if c in X_train.columns]),\n",
        "    ('cat', categorical_transformer, [c for c in categorical_cols if c in X_train.columns])\n",
        "], remainder='drop')\n",
        "\n",
        "# Fit preprocessor on training data to inspect how many output features we get\n",
        "preprocessor.fit(X_train)\n",
        "try:\n",
        "    n_cat_feats = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out().shape[0]\n",
        "except Exception:\n",
        "    n_cat_feats = 0\n",
        "n_num = len([c for c in numeric_cols if c in X_train.columns])\n",
        "print(\"Numeric features:\", n_num, \"One-hot features:\", n_cat_feats, \"Total:\", n_num + n_cat_feats)"
      ],
      "metadata": {
        "id": "zyVpOo5X0Uvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2 — Model building & experiments: Decision Tree baseline\n"
      ],
      "metadata": {
        "id": "5poQHpnbRqEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Train a Decision Tree classifier using the preprocessing pipeline and report baseline metrics (accuracy, precision, recall, F1, AUC)."
      ],
      "metadata": {
        "id": "-Achk6uOT3XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree baseline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
        "\n",
        "# Create pipeline: reuse preprocessor you fitted earlier\n",
        "dt_pipeline = Pipeline([\n",
        "    ('preproc', preprocessor),\n",
        "    ('clf', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Fit baseline\n",
        "dt_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_dt = dt_pipeline.predict(X_test)\n",
        "# Probabilities for AUC\n",
        "y_proba_dt = dt_pipeline.predict_proba(X_test)[:,1] if hasattr(dt_pipeline.named_steps['clf'], \"predict_proba\") else None\n",
        "\n",
        "# Compute metrics\n",
        "dt_acc = accuracy_score(y_test, y_pred_dt)\n",
        "dt_prec = precision_score(y_test, y_pred_dt, zero_division=0)\n",
        "dt_rec = recall_score(y_test, y_pred_dt, zero_division=0)\n",
        "dt_f1 = f1_score(y_test, y_pred_dt, zero_division=0)\n",
        "dt_auc = roc_auc_score(y_test, y_proba_dt) if y_proba_dt is not None else None\n",
        "\n",
        "print(\"Decision Tree - Baseline\")\n",
        "print(f\"Accuracy: {dt_acc:.4f}, Precision: {dt_prec:.4f}, Recall: {dt_rec:.4f}, F1: {dt_f1:.4f}\")\n",
        "if dt_auc is not None:\n",
        "    print(f\"AUC: {dt_auc:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred_dt, zero_division=0))"
      ],
      "metadata": {
        "id": "EYxZOjJBRuVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree: hyperparameter tuning\n",
        "a small GridSearchCV to improve Decision Tree performance. Keep the grid modest to save time."
      ],
      "metadata": {
        "id": "yPamV8kKUMbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV for Decision Tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'clf__criterion': ['gini', 'entropy'],\n",
        "    'clf__max_depth': [4, 8, 12, None],\n",
        "    'clf__min_samples_leaf': [1, 3, 6]\n",
        "}\n",
        "\n",
        "grid_dt = GridSearchCV(dt_pipeline, param_grid, cv=4, scoring='f1', n_jobs=-1, verbose=1)\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", grid_dt.best_params_)\n",
        "best_dt = grid_dt.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "y_pred_best_dt = best_dt.predict(X_test)\n",
        "y_proba_best_dt = best_dt.predict_proba(X_test)[:,1] if hasattr(best_dt.named_steps['clf'], \"predict_proba\") else None\n",
        "\n",
        "print(\"Tuned Decision Tree metrics:\")\n",
        "print(\"F1:\", round(f1_score(y_test, y_pred_best_dt),4),\n",
        "      \"Precision:\", round(precision_score(y_test, y_pred_best_dt, zero_division=0),4),\n",
        "      \"Recall:\", round(recall_score(y_test, y_pred_best_dt, zero_division=0),4))\n",
        "if y_proba_best_dt is not None:\n",
        "    print(\"AUC:\", round(roc_auc_score(y_test, y_proba_best_dt),4))"
      ],
      "metadata": {
        "id": "jhCXoqcWSAI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare data arrays for Neural Network\n",
        "Transform data using the fitted preprocessor so we have numeric arrays for Keras."
      ],
      "metadata": {
        "id": "hp3gwCqSapDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and get numpy arrays for NN\n",
        "X_train_proc = preprocessor.transform(X_train)\n",
        "X_test_proc = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"Preprocessed shapes -> X_train:\", X_train_proc.shape, \"X_test:\", X_test_proc.shape)"
      ],
      "metadata": {
        "id": "_D_CxOFqao2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network architecture\n",
        "Define a simple Multi-Layer Perceptron (MLP) with dropout."
      ],
      "metadata": {
        "id": "SPS77Ntcax40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple Neural Network (Keras)\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "def build_mlp(input_dim, hidden_units=[64,32], lr=1e-3):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(input_dim,)))\n",
        "    for units in hidden_units:\n",
        "        model.add(layers.Dense(units, activation='relu'))\n",
        "        model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=lr),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['AUC'])\n",
        "    return model\n",
        "\n",
        "nn_model = build_mlp(X_train_proc.shape[1], hidden_units=[64,32], lr=1e-3)\n",
        "nn_model.summary()"
      ],
      "metadata": {
        "id": "v6h6SEDebGwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Neural Network with early stopping\n",
        "Train the NN with a validation split and early stopping to avoid overfitting. Adjust epochs/batch_size as needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "R92MYaWcbiWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train NN with EarlyStopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "\n",
        "history = nn_model.fit(\n",
        "    X_train_proc, y_train.values,\n",
        "    validation_split=0.15,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Plot training curves (loss)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('NN training loss'); plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mR2O55I5bm_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Neural Network and Decision Tree (tuned)\n",
        "Compute metrics for the final models and prepare a comparison table. Plot ROC curves for both."
      ],
      "metadata": {
        "id": "GhrFysR7cYLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate NN and tuned Decision Tree\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
        "\n",
        "# NN predictions\n",
        "nn_probs = nn_model.predict(X_test_proc).ravel()\n",
        "nn_preds = (nn_probs >= 0.5).astype(int)\n",
        "\n",
        "# Tuned DT predictions (best_dt from GridSearch)\n",
        "dt_preds = best_dt.predict(X_test)\n",
        "dt_probs = best_dt.predict_proba(X_test)[:,1] if hasattr(best_dt.named_steps['clf'], \"predict_proba\") else None\n",
        "\n",
        "# Metrics function\n",
        "def binary_metrics(y_true, y_pred, y_proba=None):\n",
        "    return {\n",
        "        'Accuracy': round(accuracy_score(y_true, y_pred),4),\n",
        "        'Precision': round(precision_score(y_true, y_pred, zero_division=0),4),\n",
        "        'Recall': round(recall_score(y_true, y_pred, zero_division=0),4),\n",
        "        'F1': round(f1_score(y_true, y_pred, zero_division=0),4),\n",
        "        'AUC': round(roc_auc_score(y_true, y_proba),4) if y_proba is not None else None\n",
        "    }\n",
        "\n",
        "metrics_dt = binary_metrics(y_test, dt_preds, dt_probs)\n",
        "metrics_nn = binary_metrics(y_test, nn_preds, nn_probs)\n",
        "\n",
        "import pandas as pd\n",
        "res_df = pd.DataFrame([metrics_dt, metrics_nn], index=['DecisionTree','NeuralNet'])\n",
        "display(res_df)\n",
        "\n",
        "#  1. Train vs Test Accuracy\n",
        "plt.figure(figsize=(7,5))\n",
        "models = ['Neural Network', 'Decision Tree']\n",
        "\n",
        "train_accs = [\n",
        "    accuracy_score(y_train, nn_model.predict(X_train_proc).round()),\n",
        "    accuracy_score(y_train, best_dt.predict(X_train))\n",
        "]\n",
        "\n",
        "test_accs = [metrics_nn['Accuracy'], metrics_dt['Accuracy']]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "w = 0.35\n",
        "\n",
        "plt.bar(x - w/2, train_accs, w, label='Train', color='skyblue')\n",
        "plt.bar(x + w/2, test_accs, w, label='Test', color='salmon')\n",
        "plt.xticks(x, models)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Train vs Test Accuracy Comparison\")\n",
        "plt.legend()\n",
        "\n",
        "for i, v in enumerate(train_accs):\n",
        "    plt.text(i - w/2, v + 0.005, f\"{v:.3f}\", ha='center')\n",
        "for i, v in enumerate(test_accs):\n",
        "    plt.text(i + w/2, v + 0.005, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#  2. Generalisation Gap\n",
        "plt.figure(figsize=(7,5))\n",
        "gen_gap = [abs(train_accs[0] - test_accs[0]),\n",
        "           abs(train_accs[1] - test_accs[1])]\n",
        "\n",
        "plt.bar(models, gen_gap, color=['green', 'orange'])\n",
        "plt.axhspan(0.03, 0.05, color='lightgreen', alpha=0.3, label=\"Target range (0.03–0.05)\")\n",
        "plt.ylabel(\"Gap (Train − Test)\")\n",
        "plt.title(\"Generalisation Gap Analysis\")\n",
        "\n",
        "for i, v in enumerate(gen_gap):\n",
        "    plt.text(i, v + 0.002, f\"{v:.4f}\", ha='center')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#  3. F1-score for churn detection\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.bar(models, [metrics_nn['F1'], metrics_dt['F1']], color=['blue','orange'])\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.title(\"Churn Detection F1 Score Comparison\")\n",
        "\n",
        "for i, v in enumerate([metrics_nn['F1'], metrics_dt['F1']]):\n",
        "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 4. ROC Curve\n",
        "plt.figure(figsize=(7,5))\n",
        "\n",
        "fpr_dt, tpr_dt, _ = roc_curve(y_test, dt_probs)\n",
        "plt.plot(fpr_dt, tpr_dt, label=f\"Decision Tree (AUC={auc(fpr_dt,tpr_dt):.3f})\")\n",
        "\n",
        "fpr_nn, tpr_nn, _ = roc_curve(y_test, nn_probs)\n",
        "plt.plot(fpr_nn, tpr_nn, label=f\"Neural Network (AUC={auc(fpr_nn,tpr_nn):.3f})\")\n",
        "\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve Comparison\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix for both models\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Decision Tree confusion matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, dt_preds, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix - Decision Tree\")\n",
        "plt.show()\n",
        "\n",
        "# Neural Network confusion matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, nn_preds, cmap=\"Purples\")\n",
        "plt.title(\"Confusion Matrix - Neural Network\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "NwHyDs_VcbZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save final models\n",
        "Save the tuned Decision Tree pipeline and Keras model for submission or future use."
      ],
      "metadata": {
        "id": "0IMzpMiHeFY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models to disk\n",
        "import joblib, os\n",
        "os.makedirs('/content/models', exist_ok=True)\n",
        "\n",
        "# Save sklearn pipeline (best_dt contains preprocessor + clf)\n",
        "joblib.dump(best_dt, '/content/models/best_dt_pipeline.joblib')\n",
        "# Save Keras model\n",
        "nn_model.save('/content/models/nn_model.h5')\n",
        "\n",
        "print(\"Saved models to /content/models\")"
      ],
      "metadata": {
        "id": "OncN6s3KeMC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}